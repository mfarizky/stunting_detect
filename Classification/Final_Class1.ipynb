{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deteksi Stunting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deteksi Stunting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import time\n",
    "\n",
    "from sklearn.preprocessing import label_binarize\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn import tree\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from itertools import cycle\n",
    "\n",
    "import warnings\n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suppress FitFailedWarning\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/home/rmfarizky/Project/deteksi_stunting/Deteksi_Stunting/Classification/data_17-1.csv')\n",
    "# df = pd.read_csv('/home/rmfarizky/Project/deteksi_stunting/DRAFT/Dataset/new_draft/final_data.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_data (x):\n",
    "    fig, axs = plt.subplots(1, 3, figsize=(15, 5))\n",
    "    x.iloc[:,-3].value_counts().plot.bar(color='coral', ax=axs[0])\n",
    "    axs[0].set_title('BB/U Distribution')\n",
    "    axs[0].set_yticks(range(0, max(x.iloc[:, -3].value_counts()) + 1, 100))\n",
    "\n",
    "    x.iloc[:,-2].value_counts().plot.bar(color='coral', ax=axs[1])\n",
    "    axs[1].set_title('TB/U Distribution')\n",
    "    axs[1].set_yticks(range(0, max(x.iloc[:, -2].value_counts()) + 1, 100))\n",
    "\n",
    "    x.iloc[:,-1].value_counts().plot.bar(color='coral', ax=axs[2])\n",
    "    axs[2].set_title('BB/TB Distribution')\n",
    "    axs[2].set_yticks(range(0, max(x.iloc[:, -1].value_counts()) + 1, 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_distribution_pie(x):\n",
    "    \n",
    "    \n",
    "    fig, axs = plt.subplots(1, 3, figsize=(15, 5))\n",
    "    palette = sns.color_palette('pastel')\n",
    "\n",
    "    # Visualisasi untuk BB/U\n",
    "    bbu_counts = x.iloc[:,-3].value_counts()\n",
    "    axs[0].pie(bbu_counts, labels=bbu_counts.index, autopct='%1.1f%%', colors=palette)\n",
    "    axs[0].set_title('BB/U Distribution')\n",
    "\n",
    "    # Visualisasi untuk TB/U\n",
    "    tbu_counts = x.iloc[:,-2].value_counts()\n",
    "    axs[1].pie(tbu_counts, labels=tbu_counts.index, autopct='%1.1f%%', colors=palette)\n",
    "    axs[1].set_title('TB/U Distribution')\n",
    "\n",
    "    # Visualisasi untuk BB/TB\n",
    "    bbtb_counts = x.iloc[:,-1].value_counts()\n",
    "    axs[2].pie(bbtb_counts, labels=bbtb_counts.index, autopct='%1.1f%%', colors=palette)\n",
    "    axs[2].set_title('BB/TB Distribution')\n",
    "    \n",
    "    plt.suptitle('Perbandingan Data Pada Tiap Target Klasifikasi', fontsize=16)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_distribution_pie(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Keterangan Encoding:\n",
    "- BB/U -> {'Sangat Kurang': 0, 'Kurang': 1, 'Normal': 2, 'Risiko Lebih': 3}\n",
    "- TB/U -> {'Sangat Pendek': 0, 'Pendek': 1, 'Normal': 2, 'Tinggi': 3}\n",
    "- BB/TB -> {'Gizi Buruk': 0, 'Gizi Kurang': 1, 'Gizi Baik': 2, 'Risiko Gizi Lebih': 3, 'Gizi Lebih': 4, 'Obesitas': 5}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create correlation matrix\n",
    "corr_matrix = df.corr()\n",
    "\n",
    "# Create a mask\n",
    "mask = np.triu(np.ones_like(corr_matrix, dtype=bool))\n",
    "\n",
    "# Set the figure size\n",
    "plt.figure(figsize=(12, 10))\n",
    "\n",
    "# Create a heatmap\n",
    "sns.heatmap(corr_matrix,\n",
    "            annot=True,\n",
    "            fmt=\".2f\",  # Format for the annotations\n",
    "            mask=mask,  # To hide the upper triangle\n",
    "            cbar_kws={\"shrink\": 0.8},  # To adjust the colorbar size\n",
    "            square=True)  # To make the cells square\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pemisahan dan Pembagian Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pemisahan Fitur dan Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fitur = [\n",
    "        'JK',\n",
    "         'Usia Saat Ukur',\n",
    "         'Berat',\n",
    "         'Tinggi',\n",
    "        #'LiLA',\n",
    "        # 'ZS BB/U', \n",
    "        # 'ZS TB/U'\n",
    "        # 'ZS BB/TB'\n",
    "        ]\n",
    "# df.columns[:-6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[fitur]\n",
    "y = df[df.columns[-3:]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pembagian Data Latih dan Data Uji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "                                                    test_size=0.2,\n",
    "                                                    stratify=y[y.columns[-1]]\n",
    "                                                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_distribution_pie(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Global Variabel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = ['BB/U', 'TB/U', 'BB/TB']\n",
    "metode = ['Decision Tree', 'Naive Bayes', 'Raandom Forest']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyper-Tuning Parameter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Penyesuaian Parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the parameter grid to search\n",
    "param_grid = {\n",
    "    'estimator__max_depth': [2, 4, 8, 16, 32, 64, None],\n",
    "    'estimator__min_samples_split': [2, 10, 20, 50, 100, 200, 500]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parameter Test and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Random Forest classifier\n",
    "dt_model = DecisionTreeClassifier()\n",
    "\n",
    "# Multi-output wrapper for Random Forest classifier\n",
    "multi_output_dt = MultiOutputClassifier(dt_model)\n",
    "\n",
    "# Grid search with cross-validation\n",
    "grid_search = GridSearchCV(estimator=multi_output_dt, param_grid=param_grid, cv=5, n_jobs=-1)\n",
    "\n",
    "# Fit the grid search to the data\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best parameters and the best score\n",
    "best_params = grid_search.best_params_\n",
    "best_score = grid_search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dt_grid_result = pd.DataFrame(grid_search.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'estimator__max_depth': 16, 'estimator__min_samples_split': 2}\n",
      "Best cross-validation score: 0.6159708648170298\n",
      "Test set score of the best model: 0.6056338028169014\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"Best parameters:\", best_params)\n",
    "print(\"Best cross-validation score:\", best_score)\n",
    "\n",
    "# Evaluate the best model on the test set\n",
    "best_model = grid_search.best_estimator_\n",
    "test_score = best_model.score(X_test, y_test)\n",
    "print(\"Test set score of the best model:\", test_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Global Variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Penyesuaian Parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the parameter grid to search\n",
    "param_grid = {\n",
    "    'estimator__n_estimators': [10, 20, 60, 100, 200, 400, 600],  # Number of trees in the forest\n",
    "    'estimator__max_depth': [2, 4, 8, 16, 32, 64, None],      # Maximum depth of the trees\n",
    "    'estimator__min_samples_split': [2, 10, 20, 50, 100, 200, 500],  # Minimum number of samples required to split a node\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parameter Test and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Random Forest classifier\n",
    "rf_model = RandomForestClassifier()\n",
    "\n",
    "# Multi-output wrapper for Random Forest classifier\n",
    "multi_output_rf = MultiOutputClassifier(rf_model)\n",
    "\n",
    "# Grid search with cross-validation\n",
    "grid_search = GridSearchCV(estimator=multi_output_rf, param_grid=param_grid, cv=5, n_jobs=-1)\n",
    "\n",
    "# Fit the grid search to the data\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best parameters and the best score\n",
    "best_params = grid_search.best_params_\n",
    "best_score = grid_search.best_score_\n",
    "\n",
    "print(\"Best parameters:\", best_params)\n",
    "print(\"Best cross-validation score:\", best_score)\n",
    "\n",
    "# Evaluate the best model on the test set\n",
    "best_model = grid_search.best_estimator_\n",
    "test_score = best_model.score(X_test, y_test)\n",
    "print(\"Test set score of the best model:\", test_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define The Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Best parameters: {'estimator__max_depth': 30, 'estimator__max_fea'estimator__min_samples_split': 2}\n",
    "- Best cross-validation score: 0.9620727212610983\n",
    "- Test set score of the best model: 0.9507042253521126"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fix Parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DT_Model = DecisionTreeClassifier(max_depth=30,\n",
    "                                  max_features='sqrt',\n",
    "                                  min_samples_leaf=1,\n",
    "                                  min_samples_split=2\n",
    "            )\n",
    "start_time = time.time()\n",
    "DT_model = DT_Model.fit(X_train, y_train)\n",
    "end_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_time = end_time - start_time\n",
    "training_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DT_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_model = GaussianNB() \n",
    "NB_Model = MultiOutputClassifier(nb_model, n_jobs=-1)\n",
    "start_time = time.time()\n",
    "NB_model = NB_Model.fit(X_train, y_train)\n",
    "end_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "elapsed_time = end_time - start_time\n",
    "print(\"Waktu komputasi:\", elapsed_time, \"detik\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NB_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Best parameters: {'estimator__bootstrap': True, 'estimator__max_depth': 10, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 2, 'estimator__n_estimators': 50}\n",
    "- Best cross-validation score: 0.9977963843588024\n",
    "- Test set score of the best model: 0.9964788732394366"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RF_Model = RandomForestClassifier(bootstrap= True,\n",
    "                                  max_depth= 10,\n",
    "                                  min_samples_leaf=2,\n",
    "                                  min_samples_split=2,\n",
    "                                  n_estimators=50)\n",
    "start_time = time.time()\n",
    "RF_model = RF_Model.fit(X_train, y_train)\n",
    "end_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "elapsed_time = end_time - start_time\n",
    "print(\"Waktu komputasi:\", elapsed_time, \"detik\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RF_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pengujian dan Evaluasi Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Memprediksi Data test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DT_ypred = DT_model.predict(X_test).T\n",
    "RF_ypred = RF_model.predict(X_test).T\n",
    "NB_ypred = NB_model.predict(X_test).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Penyeragaman Bentuk Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr_X_test = np.array(X_test.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr_y_test = np.array(y_test.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrices(y_prediction, model_name):\n",
    "    def plot_confusion_matrix(y_prediction, arr_y_test):\n",
    "        labels = [c for c in range(confusion_matrix(y_prediction, arr_y_test).shape[1])]\n",
    "        sns.heatmap(confusion_matrix(arr_y_test, y_prediction), annot=True, fmt='d', cmap='Blues', xticklabels=labels, yticklabels=labels)\n",
    "        plt.xlabel('True Label')\n",
    "        plt.ylabel('Predicted Label')\n",
    "        \n",
    "\n",
    "    plt.figure(figsize=(24, 5))\n",
    "    plt.suptitle(f'Confusion Matrix {model_name} Model', fontsize=16)\n",
    "\n",
    "    for i, y_pred_T in enumerate(y_prediction):\n",
    "        plt.subplot(1, len(y_prediction), i+1)\n",
    "        plt.title(f'Confusion Matrix for {targets[i]}')\n",
    "        plot_confusion_matrix(y_pred_T, arr_y_test[i])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = ['Decision Tree', 'Naive Bayes', 'Random Forest']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrices(DT_ypred, model_name[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrices(NB_ypred, model_name[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrices(RF_ypred, model_name[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification Report "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def report_of_class(y_prediction, model_name):\n",
    "    print(f\"Laporan Klasifikasi Model {model_name}\")\n",
    "    # Inisialisasi list untuk menyimpan laporan klasifikasi\n",
    "    reports = []\n",
    "\n",
    "    # Iterasi melalui setiap variabel target\n",
    "    for i in range(y_test.shape[1]):\n",
    "        # Hitung laporan klasifikasi untuk variabel target ke-i\n",
    "        report = classification_report(arr_y_test[i], y_prediction[i])\n",
    "        # Tambahkan laporan klasifikasi ke dalam list\n",
    "        reports.append(report)\n",
    "\n",
    "    # Tampilkan laporan klasifikasi untuk setiap variabel target\n",
    "    for i, report in enumerate(reports):\n",
    "        print(f\"Laporan Klasifikasi untuk Target {targets[i]}:\")\n",
    "        print(report)\n",
    "        print(\"\\n\")  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report_of_class(DT_ypred, model_name[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report_of_class(NB_ypred, model_name[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report_of_class(RF_ypred,model_name[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Inisialisasi list untuk menyimpan nilai akurasi, presisi, recall, dan F1-score\n",
    "DT_accuracy = []\n",
    "NB_accuracy = []\n",
    "RF_accuracy = []\n",
    "\n",
    "# Iterasi melalui setiap variabel target\n",
    "for i in range(len(targets)):\n",
    "    # Hitung nilai-nilai metrik untuk variabel target ke-i\n",
    "    DT_accuracy.append(accuracy_score(arr_y_test[i, :], DT_ypred[i,:]))\n",
    "    NB_accuracy.append(accuracy_score(arr_y_test[i, :], NB_ypred[i,:]))\n",
    "    RF_accuracy.append(accuracy_score(arr_y_test[i, :], RF_ypred[i,:]))\n",
    "\n",
    "# Membuat plot\n",
    "x = np.arange(len(targets))\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "bars1 = plt.bar(x - 0.2, DT_accuracy, 0.2, label='Decision Tree')\n",
    "bars2 = plt.bar(x, NB_accuracy, 0.2, label='Naive Bayes')\n",
    "bars3 = plt.bar(x + 0.2, RF_accuracy, 0.2, label='Random Forest')\n",
    "# bars4 = plt.bar(x + 0.4, f1_scores, 0.2, label='F1-score')\n",
    "\n",
    "plt.xlabel('Targets')\n",
    "plt.ylabel('Scores')\n",
    "plt.title('Accuracy')\n",
    "plt.xticks(x, targets)\n",
    "plt.yticks(np.arange(0, 1.1, 0.1))  # Atur label pada sumbu y\n",
    "\n",
    "# Tambahkan nilai di atas setiap bar\n",
    "for bars in [bars1, bars2, bars3]:\n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        plt.text(bar.get_x() + bar.get_width() / 2, height, round(height, 2), ha='center', va='bottom')\n",
    "\n",
    "plt.legend(loc='lower right')  # Mengatur lokasi legend ke pojok kanan bawah\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Inisialisasi list untuk menyimpan nilai akurasi, presisi, recall, dan F1-score\n",
    "DT_prec = []\n",
    "NB_prec = []\n",
    "RF_prec = []\n",
    "\n",
    "# Iterasi melalui setiap variabel target\n",
    "for i in range(len(targets)):\n",
    "    # Hitung nilai-nilai metrik untuk variabel target ke-i\n",
    "    DT_prec.append(precision_score(arr_y_test[i, :], DT_ypred[i,:], average='macro'))\n",
    "    NB_prec.append(precision_score(arr_y_test[i, :], NB_ypred[i,:], average='macro'))\n",
    "    RF_prec.append(precision_score(arr_y_test[i, :], RF_ypred[i,:], average='macro'))\n",
    "\n",
    "# Membuat plot\n",
    "x = np.arange(len(targets))\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "bars1 = plt.bar(x - 0.2, DT_prec, 0.2, label='Decision Tree')\n",
    "bars2 = plt.bar(x, NB_prec, 0.2, label='Naive Bayes')\n",
    "bars3 = plt.bar(x + 0.2, RF_prec, 0.2, label='Random Forest')\n",
    "# bars4 = plt.bar(x + 0.4, f1_scores, 0.2, label='F1-score')\n",
    "\n",
    "plt.xlabel('Targets')\n",
    "plt.ylabel('Scores')\n",
    "plt.title('Precision')\n",
    "plt.xticks(x, targets)\n",
    "plt.yticks(np.arange(0, 1.1, 0.1))  # Atur label pada sumbu y\n",
    "\n",
    "# Tambahkan nilai di atas setiap bar\n",
    "for bars in [bars1, bars2, bars3]:\n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        plt.text(bar.get_x() + bar.get_width() / 2, height, round(height, 2), ha='center', va='bottom')\n",
    "\n",
    "plt.legend(loc='lower right')  # Mengatur lokasi legend ke pojok kanan bawah\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Inisialisasi list untuk menyimpan nilai akurasi, presisi, recall, dan F1-score\n",
    "DT_rec = []\n",
    "NB_rec = []\n",
    "RF_rec = []\n",
    "\n",
    "# Iterasi melalui setiap variabel target\n",
    "for i in range(len(targets)):\n",
    "    # Hitung nilai-nilai metrik untuk variabel target ke-i\n",
    "    DT_rec.append(recall_score(arr_y_test[i, :], DT_ypred[i,:], average='macro'))\n",
    "    NB_rec.append(recall_score(arr_y_test[i, :], NB_ypred[i,:], average='macro'))\n",
    "    RF_rec.append(recall_score(arr_y_test[i, :], RF_ypred[i,:], average='macro'))\n",
    "\n",
    "# Membuat plot\n",
    "x = np.arange(len(targets))\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "bars1 = plt.bar(x - 0.2, DT_rec, 0.2, label='Decision Tree')\n",
    "bars2 = plt.bar(x, NB_rec, 0.2, label='Naive Bayes')\n",
    "bars3 = plt.bar(x + 0.2, RF_rec, 0.2, label='Random Forest')\n",
    "# bars4 = plt.bar(x + 0.4, f1_scores, 0.2, label='F1-score')\n",
    "\n",
    "plt.xlabel('Targets')\n",
    "plt.ylabel('Scores')\n",
    "plt.title('Recall')\n",
    "plt.xticks(x, targets)\n",
    "plt.yticks(np.arange(0, 1.1, 0.1))  # Atur label pada sumbu y\n",
    "\n",
    "# Tambahkan nilai di atas setiap bar\n",
    "for bars in [bars1, bars2, bars3]:\n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        plt.text(bar.get_x() + bar.get_width() / 2, height, round(height, 2), ha='center', va='bottom')\n",
    "\n",
    "plt.legend(loc='lower right')  # Mengatur lokasi legend ke pojok kanan bawah\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## F1-Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Inisialisasi list untuk menyimpan nilai akurasi, presisi, recall, dan F1-score\n",
    "DT_f1score = []\n",
    "NB_f1score = []\n",
    "RF_f1score = []\n",
    "\n",
    "# Iterasi melalui setiap variabel target\n",
    "for i in range(len(targets)):\n",
    "    # Hitung nilai-nilai metrik untuk variabel target ke-i\n",
    "    DT_f1score.append(f1_score(arr_y_test[i, :], DT_ypred[i, :], average='macro'))\n",
    "    NB_f1score.append(f1_score(arr_y_test[i, :], NB_ypred[i, :], average='macro'))\n",
    "    RF_f1score.append(f1_score(arr_y_test[i, :], RF_ypred[i, :], average='macro'))\n",
    "    arr_y_test[i, :], RF_ypred[i,:]\n",
    "\n",
    "# Membuat plot\n",
    "x = np.arange(len(targets))\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "bars1 = plt.bar(x - 0.2, DT_f1score, 0.2, label='Decision Tree')\n",
    "bars2 = plt.bar(x, NB_f1score, 0.2, label='Naive Bayes')\n",
    "bars3 = plt.bar(x + 0.2, RF_f1score, 0.2, label='Random Forest')\n",
    "# bars4 = plt.bar(x + 0.4, f1_scores, 0.2, label='F1-score')\n",
    "\n",
    "plt.xlabel('Targets')\n",
    "plt.ylabel('Scores')\n",
    "plt.title('F1-Score')\n",
    "plt.xticks(x, targets)\n",
    "plt.yticks(np.arange(0, 1.1, 0.1))  # Atur label pada sumbu y\n",
    "\n",
    "# Tambahkan nilai di atas setiap bar\n",
    "for bars in [bars1, bars2, bars3]:\n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        plt.text(bar.get_x() + bar.get_width() / 2, height, round(height, 2), ha='center', va='bottom')\n",
    "\n",
    "plt.legend(loc='lower right')  # Mengatur lokasi legend ke pojok kanan bawah\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AUC-ROC Score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_yprobs (model, x_test, y_test):\n",
    "    y_probs = model.predict_proba(x_test)\n",
    "    target_binarize = []\n",
    "    n_classes = []\n",
    "\n",
    "    for i in range (y_test.T.shape[1]):\n",
    "        y_test_binarize = label_binarize(y_test[i], classes=np.unique(y_test[i]))\n",
    "        target_binarize.append(y_test_binarize)\n",
    "        n_classes.append(y_probs[i].shape[1])\n",
    "\n",
    "    return target_binarize, n_classes, y_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aucroc_curve(y_binarize, n_classes, y_probs):\n",
    "    lw = 2\n",
    "    # Compute ROC curve and ROC area for each class\n",
    "    fpr = dict()\n",
    "    tpr = dict()\n",
    "    roc_auc = dict()\n",
    "    for i in range(n_classes):\n",
    "        fpr[i], tpr[i], _ = roc_curve(y_binarize[:, i], y_probs[:, i])\n",
    "        roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "    # Compute micro-average ROC curve and ROC area\n",
    "    fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(y_binarize.ravel(), y_probs.ravel())\n",
    "    roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n",
    "    \n",
    "    # First aggregate all false positive rates\n",
    "    all_fpr = np.unique(np.concatenate([fpr[i] for i in range(n_classes)]))\n",
    "\n",
    "    # Then interpolate all ROC curves at these points\n",
    "    mean_tpr = np.zeros_like(all_fpr)\n",
    "    for i in range(n_classes):\n",
    "        mean_tpr += np.interp(all_fpr, fpr[i], tpr[i])\n",
    "\n",
    "    # Finally average it and compute AUC\n",
    "    mean_tpr /= n_classes\n",
    "\n",
    "    fpr[\"macro\"] = all_fpr\n",
    "    tpr[\"macro\"] = mean_tpr\n",
    "    roc_auc[\"macro\"] = auc(fpr[\"macro\"], tpr[\"macro\"])\n",
    "\n",
    "    # Plot all ROC curves\n",
    "    plt.plot(\n",
    "        fpr[\"micro\"],\n",
    "        tpr[\"micro\"],\n",
    "        label=\"micro-average ROC curve (area = {0:0.2f})\".format(roc_auc[\"micro\"]),\n",
    "        color=\"deeppink\",\n",
    "        linestyle=\":\",\n",
    "        linewidth=4,\n",
    "    )\n",
    "\n",
    "    plt.plot(\n",
    "        fpr[\"macro\"],\n",
    "        tpr[\"macro\"],\n",
    "        label=\"macro-average ROC curve (area = {0:0.2f})\".format(roc_auc[\"macro\"]),\n",
    "        color=\"navy\",\n",
    "        linestyle=\":\",\n",
    "        linewidth=4,\n",
    "    )\n",
    "\n",
    "    colors = cycle([\"aqua\", \"darkorange\", \"cornflowerblue\"])\n",
    "    for i, color in zip(range(n_classes), colors):\n",
    "        plt.plot(\n",
    "            fpr[i],\n",
    "            tpr[i],\n",
    "            color=color,\n",
    "            lw=lw,\n",
    "            label=\"ROC curve of class {0} (area = {1:0.2f})\".format(i, roc_auc[i]),\n",
    "        )\n",
    "\n",
    "    plt.plot([0, 1], [0, 1], \"k--\", lw=lw)\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel(\"False Positive Rate\")\n",
    "    plt.ylabel(\"True Positive Rate\")\n",
    "    plt.title(\"Receiver operating characteristic (ROC) curves\")\n",
    "    plt.legend(loc=\"lower right\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_binarize, n_classes, y_probs = compute_yprobs(DT_model, X_test, arr_y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(18, 5))\n",
    "plt.suptitle('ROC Curves Decision Tree Model', fontsize=16)  # Judul utama\n",
    "\n",
    "plt.subplot(1, 3, 1)\n",
    "aucroc_curve(target_binarize[0], n_classes[0], y_probs[0])\n",
    "plt.title('BB/U')\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "aucroc_curve(target_binarize[1], n_classes[1], y_probs[1])\n",
    "plt.title('TB/U')\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "aucroc_curve(target_binarize[2], n_classes[2], y_probs[2])\n",
    "plt.title('BB/TB')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_binarize, n_classes, y_probs = compute_yprobs(NB_model, X_test, arr_y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(18, 5))\n",
    "plt.suptitle('ROC Curves Naive Bayes Model', fontsize=16)  # Judul utama\n",
    "\n",
    "plt.subplot(1, 3, 1)\n",
    "aucroc_curve(target_binarize[0], n_classes[0], y_probs[0])\n",
    "plt.title('BB/U')\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "aucroc_curve(target_binarize[1], n_classes[1], y_probs[1])\n",
    "plt.title('TB/U')\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "aucroc_curve(target_binarize[2], n_classes[2], y_probs[2])\n",
    "plt.title('BB/TB')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_binarize, n_classes, y_probs = compute_yprobs(RF_model, X_test, arr_y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(18, 5))\n",
    "plt.suptitle('ROC Curves Random Forest Model', fontsize=16)  # Judul utama\n",
    "\n",
    "plt.subplot(1, 3, 1)\n",
    "aucroc_curve(target_binarize[0], n_classes[0], y_probs[0])\n",
    "plt.title('BB/U')\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "aucroc_curve(target_binarize[1], n_classes[1], y_probs[1])\n",
    "plt.title('TB/U')\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "aucroc_curve(target_binarize[2], n_classes[2], y_probs[2])\n",
    "plt.title('BB/TB')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Menyimpan Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(DT_model, open('model_dtm.pkl','wb'))\n",
    "pickle.dump(NB_model, open('model_nbm.pkl','wb'))\n",
    "pickle.dump(RF_model, open('model_rfm.pkl','wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = ['/home/rmfarizky/Project/deteksi_stunting/Deteksi_Stunting/Classification/model_dtm.pkl',\n",
    "              '/home/rmfarizky/Project/deteksi_stunting/Deteksi_Stunting/Classification/model_nbm.pkl',\n",
    "              '/home/rmfarizky/Project/deteksi_stunting/Deteksi_Stunting/Classification/model_rfm.pkl']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model\n",
    "with open(model_path[0], 'rb') as file:\n",
    "    model_1 = pickle.load(file)\n",
    "\n",
    "with open(model_path[1], 'rb') as file:\n",
    "    model_2 = pickle.load(file)\n",
    "    \n",
    "with open(model_path[2], 'rb') as file:\n",
    "    model_3 = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_shuffled = df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "val = df_shuffled.head()\n",
    "val[:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val[val.columns[-3:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data yang diberikan\n",
    "x_data = val[fitur]\n",
    "y_data = val[val.columns[-3:]]\n",
    "# Membuat DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_dtm = model_1.predict(x_data)\n",
    "prediction_nbm = model_2.predict(x_data)\n",
    "prediction_rfm = model_3.predict(x_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mencetak setiap variabel\n",
    "print(\"Prediction DTM:\", prediction_dtm)\n",
    "print(\"Prediction NBM:\", prediction_nbm)\n",
    "print(\"Prediction RFM:\", prediction_rfm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TESTING WITH DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv(\"/home/rmfarizky/Project/deteksi_stunting/DRAFT/Dataset/new_draft/final_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.rename(columns={'usia ukur': 'Usia Saat Ukur'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xd = df1[fitur]\n",
    "yd = df1[df.columns[-3:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_dtm = model_1.predict(Xd)\n",
    "predict_nbm = model_2.predict(Xd)\n",
    "predict_rfm = model_3.predict(Xd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inisialisasi list untuk menyimpan laporan klasifikasi\n",
    "reports = []\n",
    "targets = ['BB/U', 'TB/U', 'BB/TB']\n",
    "\n",
    "# Iterasi melalui setiap variabel target\n",
    "for i in range(y_test.shape[1]):\n",
    "    # Hitung laporan klasifikasi untuk variabel target ke-i\n",
    "    report = classification_report(np.array(yd).T[i], predict_rfm.T[i])\n",
    "    # Tambahkan laporan klasifikasi ke dalam list\n",
    "    reports.append(report)\n",
    "\n",
    "# Tampilkan laporan klasifikasi untuk setiap variabel target\n",
    "for i, report in enumerate(reports):\n",
    "    print(f\"Laporan Klasifikasi untuk Target {targets[i]}:\")\n",
    "    print(report)\n",
    "    print(\"\\n\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
